{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab session we will see explore in more detail the following:\n",
    "- Linear Regression\n",
    "- Using linear regression on real world data\n",
    "- Difference of Overfitting and Underfitting\n",
    "- Gradient Descent\n",
    "- Batch Gradient Descent\n",
    "- Stochastic Gradient Descent\n",
    "- Polynomial Regression\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be familiar with the above topics from the course lectures. So we will focus mainly on the implementation in code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start this demonstration with a simple implementation of Linear Regression for demonstrative purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Generate random dataset\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.rand(100,1)\n",
    "X_new = np.array([[0], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100, 1)), X]\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.55096698],\n",
       "       [10.40722835]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new_b = np.c_[np.ones((2,1)), X_new]\n",
    "y_predict = X_new_b.dot(theta_best)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to use the `%matplotlib inline` to use the `matplotlib` library inside Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(X_new, y_predict, \"r-\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.axis([0,2,0,15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Why are we using formula `y =  offset *X * np.random.rand(50,1) + (offset-X*offset/2)` to generate new dataset?\n",
    "Because it closely reassembles real life accuracy of prediction over time (for example weather).\n",
    "\n",
    "- Task 1: plot the data\n",
    "- Task 2: calculate linear regession for this dataset and plot it\n",
    "- Task 3: how can we increase accuracy? Try adding more points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "offset = 8\n",
    "\n",
    "X = 2 * np.random.rand(50, 1)\n",
    "y =  offset *X * np.random.rand(50,1) + (offset-X*offset/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "- Can we use linear regression for non linear functions?\n",
    "- What are the issues with this approach?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGK9JREFUeJzt3X+QJHV5x/HPs/fLgCCwdwYCnAcpQkrBeGTKuJiCJacBUcGUsQpKXUB0wXDGizHEC2VMBZOzKqmI1FGJKx7elRRqOJOgBQnkvC1MHMA9fv8IPzXn8UPWQwQx7N3tPvnj2+32DTM7P7qnp2f6/aq6mpnunumHdnzmu08//W1zdwEABt9QrwMAAOSDhA8AJUHCB4CSIOEDQEmQ8AGgJEj4AFASJHwAKAkSPgCUBAkfAEpicZ47W758ua9atSrPXQIoiZdekh5+WHKXzKTjj5cOPLDXUWVjx44dP3H3FWk/J9eEv2rVKk1NTeW5SwAlsWGD9OlPS7Oz0tCQNDYmrV/f66iyYWb/m8XnUNIBMBBGR6WlS6VFi8Lj6GivIyqeXEf4ANAtIyPStm3S5GRI9iMjvY6oeEj4AAbGyAiJfiGUdACgJEj4AFASJHwAfa9aDV061WqvIyk2avgA+lq1Kq1ZI+3ZE7pztm2jjt8II3wAfW1yMiT72dnwODnZ64iKi4QPoK/Rf9+6pgnfzDaZ2bNmdn+ddZ80Mzez5d0JDwAWFvffX3455ZxmWqnhf0XSRklbkgvN7GhJb5e0M/uwAKB19N+3pukI391vlfRcnVWfl3SpJM86KABA9jqq4ZvZWZKedPd7Mo4HABqi/TKdttsyzewASZdJ+v0Wtx+XNC5JK1eubHd3ACCJ9sssdDLC/3VJx0i6x8x+KOkoSXea2eH1Nnb3CXevuHtlxYrU0zkDKCnaL9Nre4Tv7vdJem38Okr6FXf/SYZxAcB+4vbLeIRP+2X7miZ8M7tO0qik5Wa2S9Jn3P3L3Q4MAJKY/ji9pgnf3c9tsn5VZtEAQAPVKsk+LebSAVB48QnbmZlw+8KrrpLGx3sdVf9hagUAhTc5GZL93Jy0b5+0di2tmZ0g4QMovNHRMLKPzc7SpdMJEj6AwhsZCWWcJUtC4l+2jC6dTlDDB9AXxselE0/kxG0aJHwAfYNJ0tKhpAMAJUHCB4CSIOEDQEmQ8AGgJEj4AFASJHwAKAkSPgCUBAkfAEqChA8AJUHCB4CSIOEDKIxqVdqwgamPu4W5dAAUQnyTk/ietdu2MW9O1hjhAyiEycmQ7GdnwyPz3WePhA+gEEZHw8h+0aLwyHz32Wta0jGzTZLeJelZdz8hWvZ3kt4taY+kxyVd4O7PdzNQAINtZCSUcZjvvntaGeF/RdIZNctukXSCu79R0iOS1mccF4ASGhmR1q8n2XdL04Tv7rdKeq5m2c3uvi96eZuko7oQGwAgQ1nU8D8k6aYMPgdAidCCmb9UbZlmdpmkfZKuXWCbcUnjkrRy5co0uwMwIGjB7I2OR/hmdp7Cydz3u7s32s7dJ9y94u6VFStWdLo7AAOEFsze6GiEb2ZnSPpzSae6+y+yDQnAoItbMOMRPi2Y+WilLfM6SaOSlpvZLkmfUejKWSbpFjOTpNvc/eIuxglggNCC2RtNE767n1tn8Ze7EAuAEhkZIdHnjSttAaAkSPgAeoK2zPwxWyaAXFWr0pYt0qZNoUuHtsz8kPABdEWc2CVpbCwk9Lj//uWXpbiZO27LJOF3HwkfQOaq1dB9s2dPeH3NNdL27fP993GyN6MtM0/U8AFkbnJS2rt3/nU8ik9OgbxsmXTRRZRz8sQIH0DmRkelJUvmR/jxKJ7++94i4QPI3MhISOq1Nfx4HYm+N0j4ALqCxF481PABZIbe+mJjhA8gE0x5XHyM8AFkgimPi4+EDyATyZZLeuuLiZIOgEzQcll8JHwAmaEzp9go6QBASZDwAaAkSPgAUBIkfAAoCRI+AJRE04RvZpvM7Fkzuz+x7DAzu8XMHo0eD+1umACAtFoZ4X9F0hk1yz4laZu7HydpW/QaAFBgTRO+u98q6bmaxWdL2hw93yzpPRnHBaCPMGlaf+j0wqtfdfenJcndnzaz12YYE4A+wqRp/aPrJ23NbNzMpsxsanp6utu7A5AzJk3rH50m/B+b2RGSFD0+22hDd59w94q7V1asWNHh7gAUFZOm9Y9OSzo3SDpP0ueix3/LLCIAhVet7j9JGpOm9YemCd/MrpM0Kmm5me2S9BmFRP8NM7tQ0k5J7+tmkACKI1mzX7xYuuCCcM/a9et7HRmaaZrw3f3cBqvWZBwLgD6QrNnPzkpf/KK0eTMna/sBV9oCaEtcszcLr905WdsvSPgA2hLX7C+6iJO1/YYboABoW3yjk7ExTtb2ExI+gI5xh6v+QkkHAEqChA8AJUHCB4CSIOEDQEmQ8AGgJEj4AFASJHwAKAkSPgCUBAkfAEqChA8AJUHCB4CSIOEDQEmQ8AGgJEj4AFASJHygxKpVacOG8IjBx3z4QMlUq+GmJcPD0rp14faES5dyT9oySJXwzexPJH1Ykku6T9IF7v5yFoEByN7EhLR2bbj5+KJF4XFubv6etCT8wdZxScfMjpT0x5Iq7n6CpEWSzskqMADZqlalSy6R9u4NSX52Vhoa4p60ZZK2pLNY0q+Y2V5JB0h6Kn1IALphcjIk+tiiRdLGjdLu3dyTtiw6Tvju/qSZ/b2knZL+T9LN7n5zZpEByNToqLRsmTQzE0b2GzdK4+O9jgp5SlPSOVTS2ZKOkfRrkg40sw/U2W7czKbMbGp6errzSAG0pbYDZ2QknJj97Gelq64KI3u6c8olTUnnbZJ+4O7TkmRm35R0sqSvJjdy9wlJE5JUqVQ8xf4AtKhaldaseWUHTly2qbcOgy9NH/5OSW8xswPMzCStkfRQNmEBSGNyMiT02dn5DpxW1mGwdZzw3f12SddLulOhJXNI0UgeQG+NjobRe70OnIXWYbCZe35Vlkql4lNTU7ntDyiz+AKreh04C61D8ZjZDnevpP4cEj4AFFtWCZ+5dIABx3w5iDGXDjDAGnXroJwY4QMDbHIyXGg1Oxse6cgpNxI+MMCGh+enU5ibC69RXiR8YEBVq9LWrZJZeD00FK6uRXlRwwcGUFy7n5mR4ka8JUvouS87RvjAAIqvpk3OjpljBzYKioQPDKD4atq4nCOFE7ectC03Ej4wgOKZMS+6iGkUMI8aPjCg4tkxx8aYRgEBCR8YcMlpkVFulHQAoCRI+ABQEiR8ACgJEj5QcMx2iaxw0hYosFZmu+RmJmgVCR8osHr3n00mdaY/Rjso6QAF1uz+s9yQHO1ghA8UWHzFbKOSTfyDEI/wuZIWC0mV8M3sEElXSzpBkkv6kLtzagnI0EIXTjX7QQCS0o7wvyDp3939D81sqaQDMogJQBu4khat6jjhm9nBkk6RdL4kufseSXuyCQsAkLU0J22PlTQt6Rozu8vMrjazAzOKCwCQsTQJf7GkkyT9o7uvlvSSpE/VbmRm42Y2ZWZT09PTKXYHAEgjTcLfJWmXu98evb5e4QdgP+4+4e4Vd6+sWLEixe6AwcSVtMhLxzV8d3/GzH5kZse7+8OS1kh6MLvQgMHHhVPIU9oLrz4m6Vozu1fSmyT9bfqQgPLgwinkKVVbprvfLamSUSxA6XDhFPLElbZADhpNcMaFU8gTCR/osmZ1ei6cQl6YPA3oMur0KAoSPtBlzWa8BPJCSQfoMur0KAoSPpAD6vQoAko6AFASJHwAKAkSPgCUBAkfAEqChA/0ADNkohfo0gFyxgyZ6BVG+EBK7Y7WufIWvcIIH0ihldF67cRpzJCJXiHhAynUG63HCb9albZskTZtCuuTPwhceYteIOEDKTQarccj/5dfltzDsuQPAlfeohdI+EAKjUbr8cg/TvZmlG/QeyR8IKV6o/XkyH/xYumCC6SxMUb16C0SPtAF1OlRRCR8oEuo06NoUvfhm9kiM7vLzL6dRUBAv+BqWfSbLEb4H5f0kKSDM/gsoC/U67+XKOGg2FIlfDM7StI7Jf2NpE9kEhFQALUXS9Wq7b/fskXavJnpElBsaUf4V0i6VNJBGcQCFEIrV8/W9t9LjS/AAoqi4xq+mb1L0rPuvqPJduNmNmVmU9PT053uDshNK3PdxF04l18eHsfGuFE5ii/NCP+tks4yszMlvUrSwWb2VXf/QHIjd5+QNCFJlUrFU+wPyEWrc93UduHQhomiM/f0OdjMRiV90t3ftdB2lUrFp6amUu8P6LZmNXwgT2a2w90raT+HPnyUSquJnB56DKJMEr67T0qazOKzgG7hxiMoO26AgtLgxiMoO0o6GGhxCWd4WNq5M3TRSHTSoJxI+BhYcQlnZkaam5OGhqQlS6SPfISZK1FOlHQwsOISztxceD03J+3bJ61cSbJHOZHwMbDifvqh6Fs+NEQpB+VGSQcDKzkn/fCwtHs3ffUoNxI+Bhr99MA8SjoAUBKM8NFXqtUwFbFEpw3QLhI++ka1Kp12WmizlKRNm5iGGGgHJR30jbjNMrZ3L1fLAu0g4aNvxG2WsSVLaLEE2kFJB31jZETavp0aPtApEj76RjwvDoke6AwJH4XQbJ56pjYG0iPho+daSeb1pjYm4QPt4aQteq6VeerjE7bcJBzoHCN89FwrNw1PzovDfDhAZ0j46LlWkznz4gDpkPBRCCRzoPs6ruGb2dFmtt3MHjKzB8zs41kGBgDIVpoR/j5Jf+rud5rZQZJ2mNkt7v5gRrEBADLU8Qjf3Z929zuj5y9KekjSkVkFBgDIViZtmWa2StJqSbdn8XkAgOylTvhm9mpJWyWtc/cX6qwfN7MpM5uanp5OuzsUWLUqbdgQHgEUT6ouHTNbopDsr3X3b9bbxt0nJE1IUqVS8TT7Q3HFc9XHvfTbt9N1AxRNmi4dk/RlSQ+5+z9kFxKKrNEofsuWcGMS9/AYz2gJoDjSjPDfKumDku4zs7ujZX/h7jemDwtF1M4EZs88E34YuCoWKI6OE767/5ckyzAWFNxCE5iNjYVbDu7dG+a7uekm6VvfYmZLoEi40hYtW2jOm5GR8AMwOSnt3Cl96UuvnAyNeXCA3iLhD7hm88y3o9U5b1av3v+H4fnnpVNPDT8Ay5Yx4gd6hYQ/wLpx05BGc97UdulceaW0e7c0PCxdcom0b1/YbmaGueyBXmE+/AHWbJ75LPvma7t07rpLWr8+JP25ufntFi1iLnugVxjh97mFSjYL1dzzumXg6Ggo48zMSEND0saNjO6BXiHhF0CndfZmSXuhmnvWtwxMduksWRJeN4sBQL5I+D2WZqTdStJuVHMfHg4jbvdsbhmY7NKpTezMdQ8UQ641/Gee6b95Vro9P0wr93NtpNP7vFar0rp1YZ9DQ9IVV2STkEdGQt2e5A4UU64j/CefDKPZXrXltVs6iUffMzMhqW7cKI2PZxtTK/dzbaTTckn8IzM3J5mFE6sABl/uJZ08LsSpl9g7KZ1MToZkPzcX/n30o2F5lkk/bY27k3JJmh8ZAP0r94S/dGmoH3erQ2RiQlq79pUX+XRyknJ0NIzs47bCubnw2SeemO2PVN41bk6kAuWUaw3/yCNDotm9u37dOm29vFoNF/ns3RuSc3yRj9RZvXtkJJRxhhJHaXa2vTp7UcX1dok57IGyyHWEf/jh86PJ2pJCFn3hk5ONL/LpdFQbl2+SfzW08mMRl5WGh8MPXBFH0nn14gMohp60ZdZLvhs2pO8Lb3aRz0LTAsTzt4+NvXKb8fFQxmn1xyJ5snduLsRSxDlksu7FB1BsPevDr02+WZxI7GQUX62GbffsCa+vuab+3ZraqbMnu2Ck8FjEhMrJW6BcCnPhVa9OJE5Ohpp/LIvEHCfS5Ai/iAmVk7dAuRQm4Uvpu1U6qUmPjoapAOIRflZXnV5xhbR1q/SmN0mHHBJq+cmTvUVJslwFC5RHoRJ+Wp3UpOOWzbiGv3r1fGJO9vAvVOOvFV/JumeP9N3vhuQfv168OExnMDvLiVIA+RqohN9pTToe5db7C0GSTjllfj73RjX+pNofnq1b51/HdX33+j9KWd6wBACSBirhp61J1/sLYefO+WQvtfaXQ+0Pz3vfO98yunhxmM4gHuH3YspiAOWUKuGb2RmSviBpkaSr3f1zrbyvkzltWt0+TU06ebJ1aCjU3e+4Y/9tzJr/5VD7wxO/TwqfG98NqttTFgNAUscJ38wWSbpK0tsl7ZL0fTO7wd0fXOh9jcomjRJ6nqPe+GTrJZeEpLtunXT66ftvc9ZZre0/+cOzYUP4K8E9PO7ePX+VaxJtkgC6Kc0I/82SHnP3JyTJzL4m6WxJCyb82lHsli3S5s2NE3reo97du0NijnvnDz88xBXf2OPSS9v/zFYTOW2SALopTcI/UtKPEq93SfqdZm+qTX7Swgk971Fv7f7GxsK/NEm4nUROmySAbjF37+yNZu+TdLq7fzh6/UFJb3b3j9VsNy4pnlD4BEn3SwcdKB18kPTCi2Hxcb8hySS59Ogj0osv7b+35Pa167rh1UdKr5nNb38dWy7pJ70OogX9EGc/xCgRZ9b6Jc7j3f2gtB+SZoS/S9LRiddHSXqqdiN3n5A0IUlmNuXulRT7zEWI88U+ibNfjmex4+yHGCXizFo/xZnF56SZHvn7ko4zs2PMbKmkcyTdkEVQAIDsdTzCd/d9ZrZW0n8otGVucvcHMosMAJCpVH347n6jpBvbeMtEmv3liDiz1Q9x9kOMEnFmrVRxdnzSFgDQX3K9xSEAoHcyS/hmdoaZPWxmj5nZp+qsX2ZmX4/W325mqxLr1kfLHzaz02vfm2OMnzCzB83sXjPbZmavS6ybNbO7o39dPTndQpznm9l0Ip4PJ9adZ2aPRv/O63Gcn0/E+IiZPZ9Yl8vxNLNNZvasmd3fYL2Z2ZXRf8O9ZnZSYl2ex7JZnO+P4rvXzL5nZr+VWPdDM7svOpaZdHOkiHPUzH6W+N/2LxPrFvy+5BznnyVivD/6Ph4WrcvleJrZ0Wa23cweMrMHzOzjdbbJ9vvp7qn/KZy0fVzSsZKWSrpH0utrtvkjSf8UPT9H0tej56+Ptl8m6ZjocxZlEVcHMZ4m6YDo+UfjGKPXP886phRxni9pY533Hibpiejx0Oj5ob2Ks2b7jymc2M/7eJ4i6SRJ9zdYf6akmxSuA3mLpNvzPpYtxnlyvH9J74jjjF7/UNLyghzPUUnfTvt96XacNdu+W9J38j6eko6QdFL0/CBJj9T5/3qm38+sRvi/nGbB3fdIiqdZSDpb0ubo+fWS1piZRcu/5u4z7v4DSY9Fn5e1pjG6+3Z3/0X08jaFawvy1sqxbOR0Sbe4+3Pu/lNJt0g6oyBxnivpui7F0pC73yrpuQU2OVvSFg9uk3SImR2hfI9l0zjd/XtRHFLvvputHM9G0nyv29ZmnL36bj7t7ndGz1+U9JDCDAZJmX4/s0r49aZZqA38l9u4+z5JP5M03OJ784ox6UKFX9bYq8xsysxuM7P3dCG+WKtxvjf6E+96M4svgMvrWLa1r6g0doyk7yQW53U8m2n035HnsWxX7XfTJd1sZjssXNneayNmdo+Z3WRmb4iWFfJ4mtkBColya2Jx7sfTQol7taTba1Zl+v3Maj58q7Ostv2n0TatvDcLLe/HzD4gqSLp1MTile7+lJkdK+k7Znafuz/eozi/Jek6d58xs4sV/nL6vRbfm5V29nWOpOvdfTaxLK/j2Uyvv5dtMbPTFBL+7yYWvzU6lq+VdIuZ/U80wu2FOyW9zt1/bmZnSvpXScepoMdToZzz3+6e/Gsg1+NpZq9W+MFZ5+4v1K6u85aOv59ZjfBbmWbhl9uY2WJJr1H4k6ulKRpyilFm9jZJl0k6y91n4uXu/lT0+ISkSYVf425oGqe7707E9iVJv93qe/OMM+Ec1fzJnOPxbKbRf0eex7IlZvZGSVdLOtvdd8fLE8fyWUn/ou6URFvi7i+4+8+j5zdKWmJmy1XA4xlZ6LvZ9eNpZksUkv217v7NOptk+/3M6OTDYoWTBsdo/oTMG2q2uUT7n7T9RvT8Ddr/pO0T6s5J21ZiXK1wYum4muWHSloWPV8u6VF16YRTi3EekXj+B5Ju8/kTOT+I4j00en5Yr+KMtjte4SSY9eJ4RvtYpcYnGd+p/U+K3ZH3sWwxzpUK57dOrll+oKSDEs+/J+mMHsZ5ePy/tUKi3Bkd25a+L3nFGa2PB50H9uJ4Rsdli6QrFtgm0+9nlsGfqXCW+XFJl0XL/lphpCxJr5L0z9GX9g5Jxybee1n0voclvaOLX4BmMf6npB9Lujv6d0O0/GRJ90Vf0vskXdjlL2qzODdIeiCKZ7uk30y890PRMX5M0gW9jDN6/VeSPlfzvtyOp8Lo7WlJexVGRRdKuljSxdF6U7iRz+NRLJUeHctmcV4t6aeJ7+ZUtPzY6DjeE30nLutxnGsT383blPiBqvd96VWc0TbnKzSMJN+X2/FUKMu5pHsT/7ue2c3vJ1faAkBJcKUtAJQECR8ASoKEDwAlQcIHgJIg4QNASZDwAaAkSPgAUBIkfAAoif8HdWD2oiFzCg4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y =  3 * np.power(X,3) + np.random.rand(100,1)\n",
    "\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.axis([0,2,0,15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same using **Scikit-Learn** faster and better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VPW9//HXZ5JM2BchLCIhQS0VLSKgNqCSBK24Ya29VbqguGCvS+1tL1p+1l577VWrXfD+/HmVKijWa6XutbWKJAGRgIJlccGVRRAkgksBySQz398fZxKGkGQmmZP1vJ+PRx6ZzJzlk8Pwnm++53u+x5xziIhI5xdq6wJERKR1KPBFRAJCgS8iEhAKfBGRgFDgi4gEhAJfRCQgFPgiIgGhwBcRCQgFvohIQGS25s769+/v8vLyWnOXIiId3qpVqz5xzuWku51WDfy8vDxWrlzZmrsUEenwzGyTH9tRl46ISEAo8EVEAkKBLyISEAp8EZGAUOCLiASEAl9EJCAU+CIiAaHAFxEJCAW+iEhAJA18M5trZjvM7PV6Xvt3M3Nm1r9lyhMREb+k0sJ/AJhc90kzGwqcBmz2uSYREWkBSQPfObcE2FXPS78HrgOc30WJiIj/mtWHb2ZTgK3OuTU+1yMiIi2kybNlmlk34AbgGykuPwOYAZCbm9vU3YmIiE+a08I/HMgH1pjZRuAw4DUzG1Tfws65Oc65cc65cTk5aU/nLCIizdTkFr5zbh0woObneOiPc8594mNdIiLis1SGZT4ClAMjzGyLmV3a8mWJiIjfkrbwnXNTk7ye51s1IiLSYnSlrYhIQCjwRUQCQoEvIhIQCnwRkYBQ4IuIBIQCX0QkIBT4IiIBocAXEQkIBb6ISEAo8EVEAkKBLyISEAp8EZGAUOCLiASEAl9EJCAU+CIiAaHAFxEJCAW+iEhAKPBFRAJCgS8iEhAKfBGRgEga+GY218x2mNnrCc/dYWbrzWytmT1pZn1atkwREUlXKi38B4DJdZ5bCBzjnBsFvAPM8rkuERHxWdLAd84tAXbVee4F51x1/MflwGEtUJuIiPjIjz78S4DnfNiOiIi0oLQC38xuAKqBhxtZZoaZrTSzlRUVFensTkRE0tDswDezi4Czge8551xDyznn5jjnxjnnxuXk5DR3dyIikqbM5qxkZpOB64GJzrm9/pYkIiItIZVhmY8A5cAIM9tiZpcCdwE9gYVmttrM7mnhOkVEJE1JW/jOuan1PH1/C9QiIiItSFfaiogEhAJfRCQgFPgiIgGhwBcRCQgFvohIQCjwRUQCQoEvIhIQCnwRkYBQ4IuIBIQCX0QkIBT4IiLtWXk5Q2CQH5tS4IuItFfl5TBpEoNgiB+bU+CLiLRXZWUQifi2OQW+iEh7VVgI4TAOGrzJVFMo8EVEWlt5Odx6q/e9MQUFsGgRH8NHfuy2WXe8EhGRZor3yxOJQDgMixZ5wd6QggK2wnY/dq0WvohIOuprrTfWgq/pl49Gve9lZQ1uOuZifLL3E99KVQtfRKS56mutQ+Mt+Hi/fO3rhYUHbLKyupL7XruP0o2llG0sY9TAUb6Vq8AXEWmuhlrrdZ9LDPx4vzxlZbiJE9nw1YGUvHYfGZbB9H1fJau0lGe23Mb6r/TlnBHncPrhp1NKqS/lKvBFRJqrodZ6Iy14gKf77uDpke9S8sq9bFq4CYArIqOY/vt3CUUi/D2cBS8+go0fD8BU6ru1eNMl7cM3s7lmtsPMXk947hAzW2hm78a/9/WlGhGRjqSmtX7zzfu7buo8t2PU4Sx4YwEzX5iJc97oyifWP8HTbz/NuEPHcdcZd/HmlW/yP90vqP3LwCJV2OLFvpdrNQU0uIDZKcBuYL5z7pj4c7cDu5xzt5nZz4C+zrnrk+1s3LhxbuXKlT6ULSLSfq3ZvoZ5q+dRsqGEdTvWAdAz3JP1V6/n0J6H8vm+z+mZ3ZOQJbS5Gxm9Y2arnHPj0q0raZeOc26JmeXVefpcoDD++EGgDEga+CIibaa83OtPLyxsfBhkE9fdHdnN0s1LKdlQwsWjL2Zkzkje2/Uec1bNYULuBKYeM5Xi/GLGHjqWzJAXub279D54Hwl9+82qMQXN7cMf6JzbBuCc22ZmA3ysSUTEX00d+55k3V2jRzB7+WxKNpSwYusKqmPVZIWyGD1oNCNzRnL2V87m0+s/JTszu2k1tmDYQyuctDWzGcAMgNzc3JbenYh0ZjWh2K8f7NyZejjWN5omxVCNPjCP0L59mHPEIpWEysrIHjuKO5bdwbEDj2Xm+JkU5RUxIXcC3bK6ATQt6Gt+r+Z+IDVBcwP/YzMbHG/dDwZ2NLSgc24OMAe8Pvxm7k9Egq4mFCsrIRaDUAiysxsOx8QWc5Kx7wctX1DA3a/ezXt/fYhb7l9Odnwym2qDcGEh3cPd2XndztqAT1saH0hN0dzAfwa4CLgt/v1p3yoSEalPTSjGYt7PsVjD4Vhfi7mB/nHnHB/87WFyz7+EUFU1GdldYNEinv3gWU577X2ynGE4nBnhy2bUrtto2De1eyaVDyQfJA18M3sE7wRtfzPbAvwHXtAvMLNLgc3Av7RIdSIiNWpCMbGF31A41tdinjXrgPB98YMX+cNrf6B0Qym/XFDBjErIAFwkgpWV8eTMJ8ke/hq86H1wWDgM06Ylr7M53TOtcMIWUhul09CI/0k+1yIi0rDEUGysD7+8HDZvhsx4vIXDbBs7gudXP0DJhhL+q/i/GNp7KO/teo+XN7/M1dGxXL5mISGiAFhmJhQWev3wdYMYvDlyGgvl5nbP1Izhb0G60lZE2o9kXSHJQjGhdR3LyGDJaUdy11e/4PHy8wGYXNGbqvJsOO8SLjvxMq4YewV2220QW+itbwbTpx88FUJBQeot91bqnmkOBb6ItA9pjFTZuXcnizctJvPeOzi7spJQLIbFYnzw6QdUn3gGd+YXc9YnhzD8X2ZgkXlw18Nk1my/bkA31G2Tasu9lbpnmkOBLyJN1xJjxpvYFeKc4/oXr+fjF59iyKp3Kc2Drl26cGaGEYqBOcf01cYlw66HEwu8rpj6tp9qQDel5d4K3TPNocAXkabxc8x4ikMn91btZdmHyyjZUMLeqr3MnjwbM+OLsue5d/b7hKsNFw7jFr5Apv0v3HsvOIdVV+8P9sYCO5WAbsct91Qp8EWkafwaM57C0MmH1jzE/f+4n/It5USiETJDmRTmFeKcw8z4n+4XYNE3vFE7VdXw0lKvS+bBBw8Odj8Cu5223FOlwBeRpkm1ayNZt0/CB4eLRNjy9EM8fHYupUPLeGzM1fQENn++mT1Ve7j2xGspzi/mpNyT6BHuUbsJKyraX0tGhjc6BxoO9g4e2OlKOlumnzRbpkgnkSzMU+n2KS8nVlxELFJJJAMmTYPlQ+GYAcfw6LcfZWTOyNqWfNJa5s+HefOgurpFpyZoK602W6aIyEGStZTnz4d9+8A5iERwpaWsP6IPJRtKKNlYwkXHXsSUgim8/+c5PHPvT6ieeBL/dsZ3KcwrZED3/XMxHhD2DX3IFBR4z1dXt/jUBB2dAl9EGtac0Tjl5TB3LjjnzT8Tcpy37bf89e4bAMjtnculX46EJ97gyMJCfvqXFG7SnewvhnY89r09UeCLSP2aOBpn6xdbKd1YSpe7Z3NedRUZAGY8U9CPXoWn8of8Yorzi8l/azt26qmpbbfmA2fz5pTvE9tRR9C0BgW+iNQvxdE4t7x0Cw+ueZB3dr4DwDd69mRKZoiMKFg4zPm3Pc35iestfnT/dvft87p/kp0HyMz0TspCwy34gJ+QTYUCX0TqV6eb5J8FYylZ/zSlG0t5ZesrLJm+hMxQJrsjuznykCO5YuwVFOcXM2rgKEI/WNFwa7uw0AvwaNTr45871xtKWXe5xA8cgMsvh9xcteDToMAXEU/d/vp4N8nbj93Lr7NW8OCSM4i5GF0zuzIhdwI79+5kYI+B3DLploO31Vhru6DAm68mfnEU0Wj9fz3UN+WBgj4tCnwRgfJy3KRJuMpKqrNCXPOTo/jujP/LxIKJfDRoH+8v3sCNeRdQnF/MiUNObPodnepq6OKoROqX950CXyTgtv1zG8/+7vtM3/clmQ4sEuPY9Z9SGa0EoCi/iKL8In93mmqYq1/eVwp8kY4uxaGT0ViU1dtX146FHzt4LL8q/hU53XN49cjuXBTOJFYdIzOczZUzF8DhLRy0CvNWp8AX6chSHDp5+TOX89hbj/HZvs8AOKr/URQOKwQgM5TJnFvWwjktMAOmtCsKfJH2JJXWeuIydeaj+eRvj/FE1lpKNpaw6bNNLL9sOQC9snvx7aO+TXF+MYV5hQzuOfjg7dbsr6zswJ+l01Dgi7SlxPCGlOafOWCZ2bMhHCYWqaQyFGPKtt+x/K8wpOcQivOL2Ve9jy6ZXfjt6b/11n22DAo3QkE9ge/ntMfSLinwRdpK3YC96KKkFzr98/m/0D1+R6fqyi/5ZNMbDFq0iPV/vpv/7fcRF5/+HebnF3PEIUccPA9NsjD3a9pjabfSCnwz+zfgMsAB64Dpzrl9fhQm0unVDVg4aD6YmtkiX9/xOhc8dgG9trzJohBkOYhlhviiYAyDCgoYWVDAr5qyr1TGvWs+mk6n2YFvZkOAHwEjnXNfmtkC4ELgAZ9qE+nc6rmwaM+F5/PhMw/xwmER5q29kguiF/Czk37GYb0OI7d3LsXTL2bTlH6MeH0bWUXFfCXVFngqYa5x751eul06mUBXM6sCugEfpV+SSAfT3Pu7FhTgXnwRW7wYN3EiRW/PYunmpUR7Rcnek834Q8aT2zsXgD5d+vDc957bv+6UZtSmce+B1+zAd85tNbPfAJuBL4EXnHMv+FaZSEfQxBOdkWiEFVtW1I6Fd86xZNYSDBj9xWhOzj2Z4vxiCoYW0CWzi/+1zZqV3jalQ0unS6cvcC6QD3wG/NnMvu+c+2Od5WYAMwByc3PTKFWkHUrSNx6NRckIebM83lR2E7e/fDtfVn+JYYwZPIbThp9W208/e/LsVq1NgiedLp1TgQ3OuQoAM3sCGA8cEPjOuTnAHPBucZjG/kTal/Jyb572hGl7YxNPYe321ZRuKKVkYwlLNi3h7avfZlCPQYzoN4LLx1xOcX4xpww7hb5d++7fTkv0m+skrNSRTuBvBr5uZt3wunQmAbphrQRDvLvExedqt8sv59VJIzlj6bnsXLgTgCMPOZKpx0wlEvVG4Ez92lSmfm3qgduYP9+bHjga9X/su07CSh3p9OGvMLPHgNeAauAfxFvyIp1OvBXuJk5kw1GD2PnwHYyp/JKMGMRwWG4uA06dwjmLX6M4r5ii/CIO63VY49ubNGn/fV+hZbpddBJWEqQ1Ssc59x/Af/hUi0i7FHlpMeHTz8BFIuwLxfjeNC+gSzIgjEFWFhQWMqzPMOadOy+1jdb0r9eEvZm6XaTF6Upb6bzq6xtPob98x54dlG0so2RDCaUbS/k/S0NcFIlg0ShhZ/wufA59fvlrulzyKbZ4cfO6SxL71zMzvRuC6AYf0sIU+NI51TckEeodQrm3ai/dsroBMO3JaTy09iEAeoZ7csqwU+j1jZHwzF0QiZARDlPwg1mQcxTkAOPHN7z/xj5Y1L8ubUCBL22rpUao1DckcfPm2j7zWKSS5/9wPTeu28ubFW/yyXWf0C2rG5PyJ3FU/6Mozi9m7KFjyQzF/4scdV7jdTZ1EjRQ/7q0OgW+tJ3yci8gq6q8fvB0TljW/eBI6DJx4TDVfXqTddNcXLzPPEKMWzKW0T08gesmXEckGqFbVjcuGn1R/dtvLJybMQmaSFtQ4EvbmT9//6RhkYj3c6rB2EiLuvqF53llWAZv/+b7REsX8VDfD7n73XKOjkYxIGZQ8Z2zeP7uBbVdOWlJYRI0kfZAgS8dT2KLOjOT2LGjsMpKLBbDRSLcfPMk/nN8FQCjTx1Ncd41dKk+Du55HCIRQuEwQwunwI9+6m0v3ZOl9UyCxrRp6p+XdkeBL21n2jSYN+/AoEyBKy2FSCUWjeGiUdwrr2IAoRCEw+SccR6PfeNbTMybSP9u/fevuOhwL4T79YNrrtnfGp83D0pLmx/MDZ2AVdBLO6PAl9Q0dnI1jdkiKS1Nuq5zjh17djCwx0AAZuz+X+60GNlACMgAYiHDTj0Vu+kmrk42E+Stt3rnDWr40c+uE7DSASjwJbnGZoRsymyR9X0wNBCUmz/fXDsOvmRDCfuq9/Hxv39MyEIU/MtPKPnK+5yyZBO9Hv4zVFcTCoVg9OjU7sdaWOidJE7sb1c/uwSAAl+Sa2zWxVRnZEzywbB993b6de1HVkYWNy++mV+U/QKAnG45FOUXUZxXTHWsmvArq7ik7GMoPBsuLoCvnwJXXw3V1XD77V63TnZ24x88BQVenfPnez/rgicJCAW+JNfYrIupzshY54Nhzwt/4/k+22pb8W9WvMnS6UuZkDuByUdMpld2L4rzizl6wNGELORto74PjZ07IRbbP0VBLAaVlcm7aNQFIwGkwJfkCgpg9mx4/HE4//wDgzLFK0b3jD+ebuEsLALRrExO+/BXlC+Aom1d+PW7/RnS80QOHV8BuXD8kOM5fsjxB2+kvr8maj5wKiu9sAfve79+/h4DkU5AgS/JlZfDj3/shexLL8HXvnZw6NcJ+r1Ve1n24TLvzk4bSlj50UruvPVCrtp7NNGTxnOme4l7dubwtVuvxSq3AFvguQsab5nX99dEzQfOTTfBwoVeSz8U8lr+InIABb4kl0I/fSQaYcsXWxjedzjOOQ7/78PZvns7maFMThhyArNOmsUJI6bAkOMJAz9nojdapubEKXgjZxoL/MaGP950k/dhpIudRBqkwJfk6mlZV8eqWfXRqtpRNEs3L2VYn2G8ddVbmBm3TrqVQT0GcVLuSfQI99i/rcSROondMeC1zJN1xTTU967JyESSspq5RVrDuHHj3MqVuilWRxRb9jIf/3UBg866ABs/nkufvpS5q+cCcMyAY2pv+nHuiHMxs/o30tAMlrffDn/5i9cdk2yEjUgAmdkq59y4dLejFr7UyznH+k/We33wG0so21jGrvAu3hlxNUcCl465lNOPOJ3CvEIGdB+Q2kbr6xqaNQtOOMEL/FhMk42JtCAFvgBewG/4bAM9wj0Y0H0AT61/im8t+BZf/xC+ub03x508gWHfvLA23McPbWAe+MY0NIRTN9sWaRXq0gmwrV9sre2DL9lQwqbPN/Gb037DT8f/lF1f7mLpo3dw9pWzsUgV5tcNthuahqGl5sUX6QTUpSNNtmPPDir2VHD0gKPZW7WX/DvzqYpV0bdLX4ryi5g5fiZnHnkmAId0PYQp23pBpMrfed0bO+mqoBdpUWkFvpn1Ae4DjgEccIlzrtyPwiR9n+37jMUbF9e24tftWMfJuSezZPoSumV144FvPsDInJGMGjhq/9WsidTVItKppNvCvxP4u3Pu22YWBny4m0Qn0QZdFHsie/jH9n9wUu5JAEx9fCp/f+/vdM3sykm5JzH1mKmcOvzU2uW/+7XvNr5BDXUU6VSa3YdvZr2ANcBwl+JGAtOH35QZJNPYR1XJi6z9al+ePmQHJRtKWLF1BdFYlIqZFfTr1o+lm5cSczFOHHIi2ZnZ/u5fRFpNe+jDHw5UAPPM7FhgFXCtc25PukV1eInDD/fta9qt+xpRFa3i1Y9e5ej3vqD3Wd8io3IfR4UcP7rYiJ54AjPHz6Qor4ie2T0Balv6IiKQXuBnAmOAa5xzK8zsTuBnwI2JC5nZDGAGQG5ubhq760AKCyEjwwt85+D++w+egrdul089XUDRWJTV21ez/i/zqCpZyMrKjfTcHaFf3yJ6RyKEYo4uFmJR7s/pctkvW//3FJGOxTnXrC9gELAx4eeTgb82ts7YsWNdh7FsmXO33OJ9b45vftM5L+69rx/+cP9r997rXFaWc6GQc9nZ3rLZ2S6WkeGiXbq4d5+d75xz7sPPP3RfvxS3JxNXbbgYuKiZi2VnOxcOO5eR4VzXrg3XmO7vICLtArDSNTOrE7+a3cJ3zm03sw/NbIRz7m1gEvCmD59BbS/dPvjycvjoo4Zfu+oq74YdgKusxD31FAYYUB2LsuKPv+aIs37AYb0O476e36Or+xPmogCYc966l18OubkNn0xtjfMIItKh1DMWr0muAR42s7XAaOCW9EtqB+qbAiAV5eXwr//qhXDNyWmzA27Q/dnfnyIWjR6wWs0/QszAwlkUT//P2teO/s5V3kVPofhS8Rt1M22aNy1BQyHe3N9BRDqttIZlOudWA2mfOW53mjP+vKZFvW/f/rsvhUJUFp7C4umF/LliLqX//QNytr7PokzoGg1hZjjDu4IhI4PQJZcQmjaNwQ3dYKRfP2+e91RuJK4x9CJSh660rU9zxp/XtKido2aMqmVn88dvHc5l799E7+zeFOYVUnTZNWw7rx/D12yGoiKvdZ/qfureeKRGQ903GkMvIgkU+A1J8VL/PZE9lG4s5YMua7mCKOH48y4jhM2ezWkXTObVPT/kuEHHkRHK2L/iWXX21ZBU+uIbukGJpisQkQTp9uF3DuXl3t2XypPPCrG3ai8vfvAiaz9eC8C7u97lnEfO4bo9T/L8KYfijPgJWIOdO8ntncu4Q8cdGPZNkUpffE33TUaGum9EpEHBaOE3Ns1Bkha0c441T97Dzuce5/GBO7m/y5tEohGuGHsF95x9D6MGjqJkWgkFQwvoMukftdsyv4I3lb54dd+ISAo6f+An6xKp04KOlpawcmiIj/d8zJQRU6C8nBEXXkVWtWNCpjHyjqkccdYPaq9iDVmIovwib1stEbypblPdNyKSROcP/GQ34C4sJJaVBS5GVYbj31+9mR4lP+eNkf05584d2OLFdIkZ5hyZsRBX7z0Gjpjc8P5aIngV5iLig84f+HW6RNzEiayveIuyjWXMGDuDjIICfv+rs/jkuccJ9e/Pb5/cRWZ1CFu2G5u6HAoLsXC2hjeKSIfX8e94lcI0xLtK/sr7T8zl2SH/ZE54Hdt3bwdg1YxVjBk8hk2fbSJkIYbe/Ue48Ubvr4GMDLj5Zu/iJt2NSUTaUHuYLbNlpRKyif3zmZkwfTpMm8bWo3Mp3VjKmMFjGJkzkpXDsjg95wkGZg2kOK+Y4nzvK79PPgDD+gzzttfQCVJ1qYhIJ9A+Az/ZidY5c+Dxx6Fbt9r+eReN4u69h8r77+Xb0xzLh8IvC3/JLyb+gpNzT+aNK9/gqP5HYWYN77fmBOn8+S3/O4qItLL2GfiNnWidMwd3xRW1i1pWFi4WA+cIOciKOm7POpMeM37FsYOOBaBrVldG5oxMff8PPujt98EHNemYiHQa7fPCq3ouJFq8cTHXL7ye8jtnAt7FTQAccQQWn1jMAZmZYU6e9nOOG3xc/fdpTUaTjolIJ9UuA3/f8cex6qHbWXLZN7wWNrD1/1zNsgW/5aVxAwBq56thxAggfnWrGVxySXotcl21KiKdVLvp0nln5zsseGMBpRtLeXnzy1RGKwkdGmLH3ivpd853mBqJMDUcxhbNhwnrvD7888/3JhR7/vn9/f3xaYibTVetikgn1SaBX3PrvpINJZw/8nyG9x3Oq1tf5cbSGxk9aDRXHn8lxfnFnJx7Mr1/f7c3VUFiF8usWTBjxv4NtsTVrQp6EelkWjXwd+zZwXmPnkfZxjI+2/cZAAO6D2B43+Gc+9VzqZhZQf9u/Q9cKdW5ZBTQIiKNatULr2yIueHXD6c4r5ii/CKK8ooY3HNw8hV14ZOIBFiHvPBq1MBRrPnRmqatpLAXEfFFqwZ+VigrtQVrQr5fP/jxj3UjbhERH7SbUTq1Eq+yNYNYzPuqb6ZLERFJWdrj8M0sw8z+YWbP+lHQARc+xWLeeHiNiRcRSZsfLfxrgbeAXj5s6+BRObNnw86d6sMXEUlTWoFvZofh3Y77v4Cf+FKRLnwSEWkR6bbwZwPXAT19qGU/jasXEfFds/vwzexsYIdzblWS5WaY2UozW1lRUdHc3YmISJrSOWk7AZhiZhuBPwHFZvbHugs55+Y458Y558bl5OSksTsREUlHswPfOTfLOXeYcy4PuBAocc5937fKRETEV+1yemQREfGfLxdeOefKgDI/tiUiIi1DLXwRkYBQ4IuIBIQCX0QkIBT4IiIBocAXEQkIBb6ISEAo8EVEAkKBLyISEAp8EZGAUOCLiASEAl9EJCAU+CIiAaHAFxEJCAW+iEhAKPBFRAJCgS8iEhAKfBGRgFDgi4gEhAJfRCQgFPgiIgHR7MA3s6FmVmpmb5nZG2Z2rZ+FiYiIvzLTWLca+Klz7jUz6wmsMrOFzrk3fapNRER81OwWvnNum3PutfjjfwJvAUP8KkxERPzlSx++meUBxwEr/NieiIj4L+3AN7MewOPAj51zX9Tz+gwzW2lmKysqKtLdnYiINFNagW9mWXhh/7Bz7on6lnHOzXHOjXPOjcvJyUlndyIikoZ0RukYcD/wlnPud/6VJCIiLSGdFv4E4AdAsZmtjn+d6VNdIiLis2YPy3TOLQXMx1pERKQF6UpbEZGAUOCLiASEAl9EJCAU+CIiAaHAFxEJCAW+iEhAKPBFRAJCgS8iEhAKfBGRgFDgi4gEhAJfRCQgFPgiIgGhwBcRCQgFvohIQCjwRUQCQoEvIhIQCnwRkYBQ4IuIBIQCX0QkIBT4IiIBkVbgm9lkM3vbzN4zs5/5VZSIiPiv2YFvZhnA/wPOAEYCU81spF+FiYiIv9Jp4Z8AvOec+8A5FwH+BJzrT1kiIuK3dAJ/CPBhws9b4s+JiEg7lJnGulbPc+6ghcxmADPiP1aa2etp7LO19Ac+aesiUqA6/dMRagTV6beOUucIPzaSTuBvAYYm/HwY8FHdhZxzc4A5AGa20jk3Lo19tgrV6a+OUGdHqBFUp986Up1+bCedLp1XgSPNLN/MwsCFwDN+FCUiIv5rdgvfOVdtZlcDzwMZwFzn3Bu+VSYiIr5Kp0sH59zfgL81YZU56eyvFalOf3WEOjtCjaA6/RaoOs25g86ziohIJ6SpFUREAsK3wE82zYKZZZvZo/HXV5hZXsJrs+LPv21mp/tEaP+gAAAFC0lEQVRVUzNq/ImZvWlma81skZkNS3gtamar418tenI6hTovNrOKhHouS3jtIjN7N/51URvX+fuEGt8xs88SXmuV42lmc81sR0PDgc3z3/HfYa2ZjUl4rTWPZbI6vxevb62ZLTOzYxNe22hm6+LH0pfRHGnUWWhmnyf82/4i4bVWm4olhTpnJtT4evz9eEj8tVY5nmY21MxKzewtM3vDzK6tZxl/35/OubS/8E7avg8MB8LAGmBknWWuBO6JP74QeDT+eGR8+WwgP76dDD/qakaNRUC3+ON/rakx/vNuv2tKo86LgbvqWfcQ4IP4977xx33bqs46y1+Dd2K/tY/nKcAY4PUGXj8TeA7vupKvAyta+1imWOf4mv3jTWeyIuG1jUD/dnI8C4Fn032/tHSddZY9Byhp7eMJDAbGxB/3BN6p5/+6r+9Pv1r4qUyzcC7wYPzxY8AkM7P4839yzlU65zYA78W357ekNTrnSp1ze+M/Lse7tqC1pTNlxenAQufcLufcp8BCYHI7qXMq8EgL1dIg59wSYFcji5wLzHee5UAfMxtM6x7LpHU655bF64C2e2+mcjwb0qpTsTSxzrZ6b25zzr0Wf/xP4C0Onq3A1/enX4GfyjQLtcs456qBz4F+Ka7bWjUmuhTvk7VGFzNbaWbLzeybLVBfjVTrPD/+J95jZlZzAVxrTneR8r7iXWP5QEnC0611PJNp6Pdoz1OH1H1vOuAFM1tl3pXtba3AzNaY2XNmdnT8uXZ5PM2sG15QPp7wdKsfT/O6uI8DVtR5ydf3Z1rDMhOkMs1CQ8ukNEWDD1Lej5l9HxgHTEx4Otc595GZDQdKzGydc+79NqrzL8AjzrlKM/sh3l9OxSmu65em7OtC4DHnXDThudY6nsm09fuyScysCC/wT0p4ekL8WA4AFprZ+ngLty28Bgxzzu02szOBp4AjaafHE68752XnXOJfA616PM2sB94Hzo+dc1/UfbmeVZr9/vSrhZ/KNAu1y5hZJtAb70+ulKZoaKUaMbNTgRuAKc65yprnnXMfxb9/AJThfRq3hKR1Oud2JtT2B2Bsquu2Zp0JLqTOn8yteDyTaej3aM1jmRIzGwXcB5zrnNtZ83zCsdwBPEnLdImmxDn3hXNud/zx34AsM+tPOzyecY29N1v8eJpZFl7YP+yce6KeRfx9f/p08iET76RBPvtPyBxdZ5mrOPCk7YL446M58KTtB7TMSdtUajwO78TSkXWe7wtkxx/3B96lhU44pVjn4ITH5wHL3f4TORvi9faNPz6kreqMLzcC7ySYtcXxjO8jj4ZPMp7FgSfFXmntY5linbl457fG13m+O9Az4fEyYHIb1jmo5t8aLyg3x49tSu+X1qoz/npNo7N7WxzP+HGZD8xuZBlf359+Fn8m3lnm94Eb4s/9J15LGaAL8Of4m/YVYHjCujfE13sbOKMF3wDJanwR+BhYHf96Jv78eGBd/E26Dri0hd+oyeq8FXgjXk8p8NWEdS+JH+P3gOltWWf855uA2+qs12rHE6/1tg2owmsVXQr8EPhh/HXDu5HP+/FaxrXRsUxW533ApwnvzZXx54fHj+Oa+Hvihjau8+qE9+ZyEj6g6nu/tFWd8WUuxhswkrheqx1PvG45B6xN+Hc9syXfn7rSVkQkIHSlrYhIQCjwRUQCQoEvIhIQCnwRkYBQ4IuIBIQCX0QkIBT4IiIBocAXEQmI/w8IQaGc2HF/2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Reset the dataset\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.rand(100,1)\n",
    "X_new = np.array([[0], [2]])\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_\n",
    "y_predict = lin_reg.predict(X_new)\n",
    "\n",
    "plt.plot(X_new, y_predict, \"g--\")\n",
    "plt.plot(X, y, \"r.\")\n",
    "plt.axis([0,2,0,15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression on real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a Linear Regression classifier on real life data, we will be using the `diabetes` dataset publicly available and visualising the resulted value of `theta`.\n",
    "\n",
    "## Exercise\n",
    "Split the dataset into training and testing portions. Testing dataset should be around 200 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diabetes_X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-57d40cd87a7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;31m# Train the model using the training sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiabetes_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiabetes_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Make predictions using the testing set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'diabetes_X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "### Exercise ###\n",
    "\n",
    "### Your code here ###\n",
    "\n",
    "### Exercise END ###\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "print(diabetes_y_pred[1])\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='r')\n",
    "plt.plot(diabetes_X_test, diabetes_y_pred, color='g', linewidth=1)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Underfitting and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models have polynomial features of different degrees. We can see that a linear function (polynomial with degree 1) is not sufficient to fit the training samples. This is called **underfitting**.  \n",
    "A polynomial of degree 4 approximates the true function almost perfectly. However, for higher degrees the model will **overfit** the training data, i.e. it learns the noise of the training data.  \n",
    "We evaluate quantitatively overfitting / underfitting by using cross-validation. We calculate the **mean squared error (MSE)** on the validation set, the higher, the less likely the model generalizes correctly from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 30\n",
    "degrees = [1, 4, 15]\n",
    "\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i],\n",
    "                                             include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X[:, np.newaxis], y)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, X[:, np.newaxis], y,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
    "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n",
    "        degrees[i], -scores.mean(), scores.std()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "This is an algorithm capable of finding optimal solutions to a wide range of problems.  \n",
    "The parameters are tweaked to minimise the cost function.\n",
    "\n",
    "However it is important to make sure that the **learning rate** is tweaked to an optimal value. Otherwise we can end up in a situation where the \"step\" is too small or too large. The undesired effects of that are as seen on the illustration below.\n",
    "\n",
    "![Gradient Descent](https://raw.githubusercontent.com/wOOL/COM2028/master/W4/gd.png)\n",
    "\n",
    "In addition, the cost functions very rarely look orderly like the ones used for demonstration pruposes above. Usually the have a complex shape.\n",
    "\n",
    "This poses a new challenge - to avoid the Local minimum.\n",
    "\n",
    "![Local Minimum](https://raw.githubusercontent.com/wOOL/COM2028/master/W4/local_min.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent\n",
    "\n",
    "Batch Gradient Descent, also called vanilla gradient descent, calculates the error for each example within the training dataset, but only after all training examples have been evaluated, the model gets updated. This whole process is like a cycle and called a training epoch.\n",
    "\n",
    "Advantages of it are that it’s computational efficient, it produces a stable error gradient and a stable convergence. Batch Gradient Descent has the disadvantage that the stable error gradient can sometimes result in a state of convergence that isn’t the best the model can achieve. It also requires that the entire training dataset is in memory and available to the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta =  0.1\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "\n",
    "#Generate random dataset\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.rand(100,1)\n",
    "X_new = np.array([[0], [2]])\n",
    "X_b = np.c_[np.ones((100, 1)), X]\n",
    "X_new_b = np.c_[np.ones((2,1)), X_new]\n",
    "\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_b.dot(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_path_bgd = []\n",
    "\n",
    "def plot_gradient_descent(theta, eta, theta_path=None):\n",
    "    m = len(X_b)\n",
    "    plt.plot(X, y, \"b.\")\n",
    "    n_iterations = 1000\n",
    "    for iteration in range(n_iterations):\n",
    "        if iteration < 10:\n",
    "            y_predict = X_new_b.dot(theta)\n",
    "            style = \"b-\" if iteration > 0 else \"r--\"\n",
    "            plt.plot(X_new, y_predict, style)\n",
    "        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "        theta = theta - eta * gradients\n",
    "        if theta_path is not None:\n",
    "            theta_path.append(theta)\n",
    "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "    plt.axis([0, 2, 0, 15])\n",
    "    plt.title(r\"$\\eta = {}$\".format(eta), fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "Modify the method above to plot every 100th iteration instead of first ten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the effect different learning rate values have on the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(131); plot_gradient_descent(theta, eta=0.02)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.subplot(132); plot_gradient_descent(theta, eta=0.1, theta_path=theta_path_bgd)\n",
    "plt.subplot(133); plot_gradient_descent(theta, eta=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Stochastic Gradient Descent approach picks a random instance in the training set at every step and computes the gradients based on that single distance.\n",
    "\n",
    "This makes the algorithm much faster than other approaches. Due to the stochastic nature of this algorithm it will continue to bounce even when reaching very close to the minimum and never settle down. What this means that the solution found is close to the optimal solution, but not optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate random dataset\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.rand(100,1)\n",
    "X_new = np.array([[0], [2]])\n",
    "X_b = np.c_[np.ones((100, 1)), X]\n",
    "X_new_b = np.c_[np.ones((2,1)), X_new]\n",
    "\n",
    "\n",
    "theta_path_sgd = []\n",
    "m = len(X_b)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Implementation\n",
    "n_epochs = 50\n",
    "t0, t1 = 5, 50\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) -yi)\n",
    "        eta = learning_schedule(epoch * m + i)\n",
    "        theta = theta - eta * gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "t0, t1 = 5, 50  # learning schedule hyperparameters\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "\n",
    "theta = np.random.randn(2,1)  # random initialization\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        if epoch == 0 and i < 20:                    \n",
    "            y_predict = X_new_b.dot(theta)          \n",
    "            style = \"b-\" if i > 0 else \"r--\"      \n",
    "            plt.plot(X_new, y_predict, style)    \n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        eta = learning_schedule(epoch * m + i)\n",
    "        theta = theta - eta * gradients\n",
    "        theta_path_sgd.append(theta)                \n",
    "\n",
    "plt.plot(X, y, \"b.\")                                \n",
    "plt.xlabel(\"$x_1$\", fontsize=18)              \n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)       \n",
    "plt.axis([0, 2, 0, 15])                        \n",
    "plt.show()                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(max_iter=50, tol=-np.infty, penalty=None, eta0=0.1, random_state=42)\n",
    "sgd_reg.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial Regression is a form of linear regression in which the relationship between the independent variable x and dependent variable y is modeled as an n-th degree polynomial.  \n",
    "\n",
    "Polynomial regression fits a nonlinear relationship between the value of x and the corresponding conditional mean of y, denoted `E(y |x)`\n",
    "\n",
    "If you need more information please read the following article in full:\n",
    "https://www.geeksforgeeks.org/python-implementation-of-polynomial-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "m = 100\n",
    "X = 6 * np.random.rand(m, 1) - 3\n",
    "y = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have generated data, we can plot it for better visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(X, y, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([-3, 3, 0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to plot our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new=np.linspace(-3, 3, 100).reshape(100, 1)\n",
    "X_new_poly = poly_features.transform(X_new)\n",
    "y_new = lin_reg.predict(X_new_poly)\n",
    "plt.plot(X, y, \"b.\")\n",
    "plt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.axis([-3, 3, 0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to consider which degree is most suitable, avoid **overfit** or **underfit**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages** of using Polynomial Regression:\n",
    "\n",
    "- Broad range of function can be fit under it.\n",
    "- Polynomial basically fits wide range of curvature.\n",
    "- Polynomial provides the best approximation of the relationship between dependent and independent variable.\n",
    "\n",
    "**Disadvantages** of using Polynomial Regression\n",
    "\n",
    "- These are too sensitive to the outliers.\n",
    "- The presence of one or two outliers in the data can seriously affect the results of a nonlinear analysis.\n",
    "- In addition there are unfortunately fewer model validation tools for the detection of outliers in nonlinear regression than there are for linear regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "for style, width, degree in ((\"g-\", 1, 300), (\"b--\", 2, 2), (\"r-+\", 2, 1)):\n",
    "    polybig_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    std_scaler = StandardScaler()\n",
    "    lin_reg = LinearRegression()\n",
    "    polynomial_regression = Pipeline([\n",
    "            (\"poly_features\", polybig_features),\n",
    "            (\"std_scaler\", std_scaler),\n",
    "            (\"lin_reg\", lin_reg),\n",
    "        ])\n",
    "    polynomial_regression.fit(X, y)\n",
    "    y_newbig = polynomial_regression.predict(X_new)\n",
    "    plt.plot(X_new, y_newbig, style, label=str(degree), linewidth=width)\n",
    "\n",
    "plt.plot(X, y, \"b.\", linewidth=3)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([-3, 3, 0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output for linear regression is a number that has its real meaning. Logistic Regression (also called Logit Regression) is commonly used to estimate the probability that an instance belongs to a particular class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = np.linspace(-10, 10, 100)\n",
    "sig = 1 / (1 + np.exp(-t))\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.plot([-10, 10], [0, 0], \"k-\")\n",
    "plt.plot([-10, 10], [0.5, 0.5], \"k:\")\n",
    "plt.plot([-10, 10], [1, 1], \"k:\")\n",
    "plt.plot([0, 0], [-1.1, 1.1], \"k-\")\n",
    "plt.plot(t, sig, \"b-\", linewidth=2, label=r\"$\\sigma(t) = \\frac{1}{1 + e^{-t}}$\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.legend(loc=\"upper left\", fontsize=20)\n",
    "plt.axis([-10, 10, -0.1, 1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output for a logistic regression is a number that represents the probability of the event happening. Logistic regression is to transform the output of a linear regression which has a wider range, to a range that probability lies in [0,1]. The transformation formula is logit that maps a value to a number in the range of [0,1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the **Iris plants dataset** and explore the implementation on a real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[\"data\"][:, 3:]  # petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.int)  # 1 if Iris-Virginica, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision boundary helps to differentiate probabilities into positive class and negative class.  \n",
    "\n",
    "**Linear Decision Boundary**\n",
    "![Decision Boundary](https://raw.githubusercontent.com/wOOL/COM2028/master/W4/db_linear.jpeg)\n",
    "\n",
    "**Non Linear Decision Boundary**\n",
    "![Decision Boundary](https://raw.githubusercontent.com/wOOL/COM2028/master/W4/db_non_linear.jpeg)\n",
    "https://towardsdatascience.com/understanding-logistic-regression-9b02c2aec102\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(X[y==0], y[y==0], \"bs\")\n",
    "plt.plot(X[y==1], y[y==1], \"g^\")\n",
    "plt.plot([decision_boundary, decision_boundary], [-1, 2], \"k:\", linewidth=2)\n",
    "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris-Virginica\")\n",
    "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris-Virginica\")\n",
    "plt.text(decision_boundary+0.02, 0.15, \"Decision  boundary\", fontsize=14, color=\"k\", ha=\"center\")\n",
    "plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width=0.05, head_length=0.1, fc='b', ec='b')\n",
    "plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width=0.05, head_length=0.1, fc='g', ec='g')\n",
    "plt.xlabel(\"Petal width (cm)\", fontsize=14)\n",
    "plt.ylabel(\"Probability\", fontsize=14)\n",
    "plt.legend(loc=\"center left\", fontsize=14)\n",
    "plt.axis([0, 3, -0.02, 1.02])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.predict([[1.7], [1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.int)\n",
    "\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", C=10**10, random_state=42)\n",
    "log_reg.fit(X, y)\n",
    "\n",
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(2.9, 7, 500).reshape(-1, 1),\n",
    "        np.linspace(0.8, 2.7, 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "\n",
    "y_proba = log_reg.predict_proba(X_new)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"g^\")\n",
    "\n",
    "zz = y_proba[:, 1].reshape(x0.shape)\n",
    "contour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)\n",
    "\n",
    "\n",
    "left_right = np.array([2.9, 7])\n",
    "boundary = -(log_reg.coef_[0][0] * left_right + log_reg.intercept_[0]) / log_reg.coef_[0][1]\n",
    "\n",
    "plt.clabel(contour, inline=1, fontsize=12)\n",
    "plt.plot(left_right, boundary, \"k--\", linewidth=3)\n",
    "plt.text(3.5, 1.5, \"Not Iris-Virginica\", fontsize=14, color=\"b\", ha=\"center\")\n",
    "plt.text(6.5, 2.3, \"Iris-Virginica\", fontsize=14, color=\"g\", ha=\"center\")\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.axis([2.9, 7, 0.8, 2.7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
    "y = iris[\"target\"]\n",
    "\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10, random_state=42)\n",
    "softmax_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, x1 = np.meshgrid(\n",
    "        np.linspace(0, 8, 500).reshape(-1, 1),\n",
    "        np.linspace(0, 3.5, 200).reshape(-1, 1),\n",
    "    )\n",
    "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
    "\n",
    "\n",
    "y_proba = softmax_reg.predict_proba(X_new)\n",
    "y_predict = softmax_reg.predict(X_new)\n",
    "\n",
    "zz1 = y_proba[:, 1].reshape(x0.shape)\n",
    "zz = y_predict.reshape(x0.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(X[y==2, 0], X[y==2, 1], \"g^\", label=\"Iris-Virginica\")\n",
    "plt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Iris-Versicolor\")\n",
    "plt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Iris-Setosa\")\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "\n",
    "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
    "contour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg)\n",
    "plt.clabel(contour, inline=1, fontsize=12)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"center left\", fontsize=14)\n",
    "plt.axis([0, 7, 0, 3.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_reg.predict([[5, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_reg.predict_proba([[5, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
